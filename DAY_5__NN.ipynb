{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TK-gNAU6V0o9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets , transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "OxnHeYAgV5bc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaX9Hqi1V6qB",
        "outputId": "b0f2b44a-17fe-4d59-f620-2bcac80efdd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 268kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.06MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 30.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data , batch_size = 64 , shuffle = True )\n",
        "test_dataloader = DataLoader(test_data  , shuffle = False  , batch_size = 64)"
      ],
      "metadata": {
        "id": "ko3p6D_QV72D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image , label = (next(iter(train_dataloader)))\n",
        "images, labels = next(iter(train_dataloader))\n",
        "print(images.shape)   # torch.Size([32, 1, 28, 28])\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbodlt0rWpZH",
        "outputId": "92357e5f-c7a9-459a-d9c3-30ccfc10edd3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class ANN(nn.Module) :\n",
        "  def __init__(self , input_size ):\n",
        "\n",
        "    super(ANN , self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "\n",
        "      nn.Linear(in_features=input_size , out_features=64) ,\n",
        "      nn.BatchNorm1d(64) ,\n",
        "      nn.ReLU() ,\n",
        "      nn.Dropout(p = 0.3) ,\n",
        "\n",
        "\n",
        "      nn.Linear(in_features=64 , out_features=128) ,\n",
        "      nn.BatchNorm1d(128) ,\n",
        "      nn.ReLU() ,\n",
        "      nn.Dropout(p = 0.3) ,\n",
        "\n",
        "      nn.Linear(in_features=128 , out_features=64) ,\n",
        "      nn.BatchNorm1d(64) ,\n",
        "      nn.ReLU() ,\n",
        "      nn.Dropout(p = 0.3) ,\n",
        "\n",
        "      nn.Linear(in_features=64 , out_features=10)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self , x) :\n",
        "\n",
        "    x = x.view(x.size(0), -1)   # flatten from [B, 1, 28, 28] → [B, 784]\n",
        "    return self.model(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "k5Eu38QqWvc6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANN(input_size= 28 * 28 )"
      ],
      "metadata": {
        "id": "YChPy_mDZF1G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "Adam_optim = torch.optim.Adam(model.parameters() , lr = lr )\n",
        "SGD_optim = torch.optim.SGD(model.parameters() , lr = lr )\n",
        "RMSProp_optim = torch.optim.RMSprop(model.parameters() , lr = lr )"
      ],
      "metadata": {
        "id": "1Xkq5PtFZLYY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAINING WITH ADAM OPTIMIZER\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    Adam_train_loss = 0.0\n",
        "    Adam_test_loss = 0.0\n",
        "    for X_batch, y_batch in train_dataloader:\n",
        "        outputs = model(X_batch)\n",
        "        loss = loss_fn(outputs, y_batch)\n",
        "        Adam_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        Adam_optim.step()\n",
        "        Adam_train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X_batch, y_batch in test_dataloader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = loss_fn(outputs, y_batch)\n",
        "            Adam_test_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = Adam_train_loss / len(train_dataloader)\n",
        "    avg_test_loss = Adam_test_loss / len(test_dataloader)\n",
        "    print(f\"Epoch: {epoch} , Train_loss: {avg_train_loss:.4f} , Test_loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTRAINING WITH RMSprop OPTIMIZER\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    RMS_train_loss = 0.0\n",
        "    RMS_test_loss = 0.0\n",
        "    for X_batch, y_batch in train_dataloader:\n",
        "        outputs = model(X_batch)\n",
        "        loss = loss_fn(outputs, y_batch)\n",
        "        RMSProp_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        RMSProp_optim.step()\n",
        "        RMS_train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X_batch, y_batch in test_dataloader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = loss_fn(outputs, y_batch)\n",
        "            RMS_test_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = RMS_train_loss / len(train_dataloader)\n",
        "    avg_test_loss = RMS_test_loss / len(test_dataloader)\n",
        "    print(f\"Epoch: {epoch} , Train_loss: {avg_train_loss:.4f} , Test_loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nTRAINING WITH SGD OPTIMIZER\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    SGD_train_loss = 0.0\n",
        "    SGD_test_loss = 0.0\n",
        "    for X_batch, y_batch in train_dataloader:\n",
        "        outputs = model(X_batch)\n",
        "        loss = loss_fn(outputs, y_batch)\n",
        "        SGD_optim.zero_grad()\n",
        "        loss.backward()\n",
        "        SGD_optim.step()\n",
        "        SGD_train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X_batch, y_batch in test_dataloader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = loss_fn(outputs, y_batch)\n",
        "            SGD_test_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = SGD_train_loss / len(train_dataloader)\n",
        "    avg_test_loss = SGD_test_loss / len(test_dataloader)\n",
        "    print(f\"Epoch: {epoch} , Train_loss: {avg_train_loss:.4f} , Test_loss: {avg_test_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5t4LL7DdrLN",
        "outputId": "d2723949-172e-4930-ccaa-2de7cb335b29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING WITH ADAM OPTIMIZER\n",
            "Epoch: 0 , Train_loss: 0.4121 , Test_loss: 0.3644\n",
            "Epoch: 1 , Train_loss: 0.4075 , Test_loss: 0.3696\n",
            "Epoch: 2 , Train_loss: 0.4066 , Test_loss: 0.3541\n",
            "Epoch: 3 , Train_loss: 0.3941 , Test_loss: 0.3590\n",
            "Epoch: 4 , Train_loss: 0.3944 , Test_loss: 0.3609\n",
            "Epoch: 5 , Train_loss: 0.3867 , Test_loss: 0.3541\n",
            "Epoch: 6 , Train_loss: 0.3813 , Test_loss: 0.3515\n",
            "Epoch: 7 , Train_loss: 0.3829 , Test_loss: 0.3380\n",
            "Epoch: 8 , Train_loss: 0.3754 , Test_loss: 0.3434\n",
            "Epoch: 9 , Train_loss: 0.3715 , Test_loss: 0.3446\n",
            "\n",
            "TRAINING WITH RMSprop OPTIMIZER\n",
            "Epoch: 0 , Train_loss: 0.3836 , Test_loss: 0.3490\n",
            "Epoch: 1 , Train_loss: 0.3723 , Test_loss: 0.3447\n",
            "Epoch: 2 , Train_loss: 0.3659 , Test_loss: 0.3418\n",
            "Epoch: 3 , Train_loss: 0.3631 , Test_loss: 0.3380\n",
            "Epoch: 4 , Train_loss: 0.3609 , Test_loss: 0.3401\n",
            "Epoch: 5 , Train_loss: 0.3586 , Test_loss: 0.3406\n",
            "Epoch: 6 , Train_loss: 0.3593 , Test_loss: 0.3378\n",
            "Epoch: 7 , Train_loss: 0.3538 , Test_loss: 0.3376\n",
            "Epoch: 8 , Train_loss: 0.3535 , Test_loss: 0.3428\n",
            "Epoch: 9 , Train_loss: 0.3519 , Test_loss: 0.3361\n",
            "\n",
            "TRAINING WITH SGD OPTIMIZER\n",
            "Epoch: 0 , Train_loss: 0.3437 , Test_loss: 0.3348\n",
            "Epoch: 1 , Train_loss: 0.3386 , Test_loss: 0.3336\n",
            "Epoch: 2 , Train_loss: 0.3309 , Test_loss: 0.3326\n",
            "Epoch: 3 , Train_loss: 0.3330 , Test_loss: 0.3314\n",
            "Epoch: 4 , Train_loss: 0.3320 , Test_loss: 0.3307\n",
            "Epoch: 5 , Train_loss: 0.3295 , Test_loss: 0.3305\n",
            "Epoch: 6 , Train_loss: 0.3326 , Test_loss: 0.3304\n",
            "Epoch: 7 , Train_loss: 0.3259 , Test_loss: 0.3304\n",
            "Epoch: 8 , Train_loss: 0.3326 , Test_loss: 0.3278\n",
            "Epoch: 9 , Train_loss: 0.3252 , Test_loss: 0.3320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `SGD` performed the best overall — its test loss is lowest and stable by the end.\n",
        "* `Adam` showed fastest convergence, but plateaued early around 0.34–0.35 test loss.\n",
        "* `RMSprop` sits between Adam and SGD — moderate speed and stability."
      ],
      "metadata": {
        "id": "MXX0RzSpuEMa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I18PXQdyuC08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}